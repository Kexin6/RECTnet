# -*- coding: utf-8 -*-
"""emotion_detection_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cdUaPboo6Fn4A1i8r4M4tn5FYs4jrlvi
"""

import numpy as np
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
from torch.utils.data.sampler import SubsetRandomSampler
import torchvision.transforms as transforms
import matplotlib.pyplot as plt # for plotting
import torch.optim as optim #for gradient descent

torch.manual_seed(1) # set the random seed

# from google.colab import drive
# drive.mount('/content/drive')

# obtain data
from torchvision import datasets, transforms

# PATH_OF_DATA = "/content/drive/My Drive/APS360/Emotion_Detection_CNN"
PATH_OF_DATA = "/base_img"

###############################################################################

def get_relevant_indices(dataset, classes, target_classes):
    """ Return the indices for datapoints in the dataset that belongs to the
    desired target classes, a subset of all possible classes.

    Args:
        dataset: Dataset object
        classes: A list of strings denoting the name of each class
        target_classes: A list of strings denoting the name of desired classes
                        Should be a subset of the 'classes'
    Returns:
        indices: list of indices that have labels corresponding to one of the
                 target classes
    """
    indices = []
    for i in range(len(dataset)):
        # Check if the label is in the target classes
        label_index = dataset[i][1] # ex: 3
        #print(label_index)
        label_class = classes[label_index] # ex: 'A'
        if label_class in target_classes:
            indices.append(i)
    return indices


def normalize_label(labels):
    """
    Given a tensor containing 2 possible values, normalize this to 0/1

    Args:
        labels: a 1D tensor containing two possible scalar values
    Returns:
        A tensor normalize to 0/1 value
    """
    max_val = torch.max(labels)
    min_val = torch.min(labels)
    norm_labels = (labels - min_val)/(max_val - min_val)
    return norm_labels

###############################################################################
# Training
def get_model_name(name, batch_size, learning_rate, epoch):
    """ Generate a name for the model consisting of all the hyperparameter values

    Args:
        config: Configuration object containing the hyperparameters
    Returns:
        path: A string with the hyperparameter name and value concatenated
    """
    path = "model_{0}_bs{1}_lr{2}_epoch{3}".format(name,
                                                   batch_size,
                                                   learning_rate,
                                                   epoch)
    return path

###############################################################################
# Training Curve
def plot_training_curve(path):
    """ Plots the training curve for a model run, given the csv files
    containing the train/validation error/loss.

    Args:
        path: The base path of the csv files produced during training
    """
    train_err = np.loadtxt("{}_train_err.csv".format(path))
    val_err = np.loadtxt("{}_val_err.csv".format(path))
    train_loss = np.loadtxt("{}_train_loss.csv".format(path))
    val_loss = np.loadtxt("{}_val_loss.csv".format(path))
    plt.title("Train vs Validation Error")
    n = len(train_err) # number of epochs
    plt.plot(range(1,n+1), train_err, label="Train")
    plt.plot(range(1,n+1), val_err, label="Validation")
    plt.xlabel("Epoch")
    plt.ylabel("Error")
    plt.legend(loc='best')
    plt.show()
    plt.title("Train vs Validation Loss")
    plt.plot(range(1,n+1), train_loss, label="Train")
    plt.plot(range(1,n+1), val_loss, label="Validation")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend(loc='best')
    plt.show()

def get_data_loader(data_path, target_classes, batch_size):
    """ Returns the indices for datapoints in the dataset that
    belongs to the desired target classes, a subset of all possible classes.

    Args:

        data_path: Path of the data
        classes: A list of strings denoting the name of each class
        target_classes: A list of strings denoting the name of the desired
                        classes. Should be a subset of the argument 'classes'
    Returns:
        indices: list of indices that have labels corresponding to one of the
                 target classes
    """
    classes = ('AF', 'AN', 'DI', 'HA', 'NE', 'SA', 'SU')
    # Even though the data collected only include A-I, I still include all alphabate for possible futrue extension
    ########################################################################
    # The output of torchvision datasets are PILImage images of range [0, 1].
    # We transform them to Tensors of normalized range [-1, 1].
    torch.manual_seed(1000)
    transform = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
    train_set = torchvision.datasets.ImageFolder(root= data_path+"/train", transform = transform)
    val_set = torchvision.datasets.ImageFolder(root= data_path+"/val", transform = transform)
    test_set = torchvision.datasets.ImageFolder(root= data_path+"/test", transform = transform)
    np.random.seed(1000) # Fixed numpy random seed for reproducible shuffling
    # Get the list of indices to sample from
    # relevant_train_indices = get_relevant_indices(
    #         train_set,
    #         classes,
    #         target_classes)
    # #np.random.shuffle(relevant_train_indices)
    
    
    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,
                                               num_workers=1, shuffle=True)

    val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size,
                                              num_workers=1, shuffle=True)
    
    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,
                                             num_workers=1, shuffle=True)
    #print("length of train data: {}".format(len(train_loader)))
    return train_loader, val_loader, test_loader, classes

def get_accuracy(model, data, train=False):

    correct = 0
    total = 0
    #for imgs, labels in torch.utils.data.DataLoader(data, batch_size=64):
    for imgs, labels in data: 
        
        #############################################
        #To Enable GPU Usage
        if use_cuda and torch.cuda.is_available():
          imgs = imgs.cuda()
          labels = labels.cuda()
        #############################################
        
        
        output = model(imgs)
        
        #select index with maximum prediction score
        pred = output.max(1, keepdim=True)[1]
        correct += pred.eq(labels.view_as(pred)).sum().item()
        total += imgs.shape[0]
    return correct / total

def train(model, data_path, batch_size=64, learning_rate=0.01, num_epochs=1):
    target_classes = ['AF', 'AN', 'DI', 'HA', 'NE', 'SA', 'SU']
    train_feature, val_feature, test_feature = get_feature_loader(batch_size)
    # Fixed PyTorch random seed for reproducible result
    torch.manual_seed(1000)
    
    # Obtain the PyTorch data loader objects to load batches of the datasets
    
    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)
    #optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    # print(model.parameters())
    iters, viters, train_losses, val_losses, train_acc, val_acc = [], [], [], [], [], []

    # training
    n = 0 # the number of iterations
    m = 0
    for epoch in range(num_epochs):
        train_loss_tot = 0
        val_loss_tot = 0
        train_item = 0
        val_item = 0
        print("Starting epoch ", epoch)

        for features, labels in iter(train_feature):
            #############################################
            #To Enable GPU Usage
            if use_cuda and torch.cuda.is_available():
              features = features.cuda()
              labels = labels.cuda()
            #############################################
            
              
            out = model(features)             # forward pass
            loss = criterion(out, labels) # compute the total loss
            loss.backward()               # backward pass (compute parameter updates)
            optimizer.step()              # make the updates for each parameter
            optimizer.zero_grad()         # a clean up step for PyTorch
            train_loss_tot += loss
            train_item += 1
            iters.append(n)
            n += 1

              
        for features, labels in iter(val_feature):
           #############################################
            #To Enable GPU Usage
            if use_cuda and torch.cuda.is_available():
              features = features.cuda()
              labels = labels.cuda()
            #############################################
            
            out = model(features)             # forward pass
            loss = criterion(out, labels) # compute the total loss
            val_loss_tot += loss
            val_item += 1
            viters.append(m)
            m += 1
              
        # save the training info for every few (1) epoches:
        #iters.append(n)
        train_losses.append(float(train_loss_tot)/train_item)             # compute *average* loss
        get_acc = get_accuracy(model, train_feature)
        train_acc.append(get_acc) # compute training accuracy 

        val_losses.append(float(val_loss_tot)/val_item)             # compute *average* loss
        get_acc_val = get_accuracy(model, val_feature)
        val_acc.append(get_acc_val)  # compute validation accuracy

        #print("Iter {}: ".format(n))
        print("Train loss: {}, Train acc: {}".format(float(train_loss_tot)/train_item, get_acc))
        print("Validation loss: {}, Validation acc: {}".format(float(val_loss_tot)/val_item, get_acc_val))
  
        # (checkpoint)
        model_path = get_model_name(model.name, batch_size, learning_rate, epoch)
        torch.save(model.state_dict(), model_path)  
        # for plotting later (checkpoint)
        np.savetxt("{}_train_loss.csv".format(model_path), train_losses)
        np.savetxt("{}_train_acc.csv".format(model_path), train_acc)
        np.savetxt("{}_val_loss.csv".format(model_path), val_losses)
        np.savetxt("{}_val_acc.csv".format(model_path), val_acc)      
    print("Finished training")


def plot_training_curve(path):
    import matplotlib.pyplot as plt

    train_losses = np.loadtxt("{}_train_loss.csv".format(path))
    train_acc = np.loadtxt("{}_train_acc.csv".format(path))
    val_losses = np.loadtxt("{}_val_loss.csv".format(path))
    val_acc = np.loadtxt("{}_val_acc.csv".format(path))

    plt.title("Training Curve")

    n = len(train_losses)
    m = len(val_losses)
    # print(n, m)
    plt.plot(range(1, n + 1), train_losses, label="Train")
    plt.plot(range(1, m + 1), val_losses, label="Validation")
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.legend(loc='best')
    plt.show()

    plt.title("Training Curve")
    plt.plot(range(1, n + 1), train_acc, label="Train")
    plt.plot(range(1, m + 1), val_acc, label="Validation")
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")
    plt.legend(loc='best')
    plt.show()
    print("Final Training Loss: {}".format(train_losses[-1]))
    print("Final Validation Loss: {}".format(val_losses[-1]))
    print("Final Training Accuracy: {}".format(train_acc[-1]))
    print("Final Validation Accuracy: {}".format(val_acc[-1]))

# import torchvision.models
# torchvision.models.inception.inception_v3(pretrained=True)
import torchvision.models
alexnet = torchvision.models.alexnet(pretrained=True)

# img = ... a PyTorch tensor with shape [N,3,224,224] containing hand images ...
def dataset_to_features(data_set):
  feature_set = []
  for imgs, labels in data_set:
    features = alexnet.features(imgs)
    features = torch.from_numpy(features.detach().numpy())
    feature_set.append((features, labels))
  return feature_set

# test if works
train_loader, val_loader, test_loader, classes = get_data_loader( 
    PATH_OF_DATA,
    target_classes=['AF', 'AN', 'DI', 'HA', 'NE', 'SA', 'SU'], 
    batch_size=1)


k = 0
for images, labels in train_loader:
    # since batch_size = 1, there is only 1 image in `images`
    image = images[0]
    # place the colour channel at the end, instead of at the beginning
    img = np.transpose(image, [1,2,0])
    # normalize pixel intensity values to [0, 1]
    img = img / 2 + 0.5
    plt.subplot(3, 5, k+1)
    plt.axis('off')
    plt.imshow(img)

    k += 1
    if k > 14:
        break

def get_feature_loader(data_path, batch_size=1):
  train_loader, val_loader, test_loader, classes = get_data_loader( 
      PATH_OF_DATA,
      target_classes = ['AF', 'AN', 'DI', 'HA', 'NE', 'SA', 'SU'], 
      batch_size=batch_size)
  train_feature = dataset_to_features(train_loader)
  val_feature = dataset_to_features(val_loader)
  test_feature = dataset_to_features(test_loader)
  return train_feature, val_feature, test_feature

import os
import torchvision.models
alexnet = torchvision.models.alexnet(pretrained=True)

# location on Google Drive
# master_path = '/content/drive/My Drive/APS360/Emotion_Detection_CNN'
master_path = '/base_img'
# Prepare Dataloader (requires code from 1.)
train_loader, val_loader, test_loader, classes = get_data_loader( 
      PATH_OF_DATA,
      target_classes = ['AF', 'AN', 'DI', 'HA', 'NE', 'SA', 'SU'], 
      batch_size=1)
print("so far so good")
target_classes = ['AF', 'AN', 'DI', 'HA', 'NE', 'SA', 'SU']

# save features to folder as tensors
n = 0
for img, label in train_loader:
  features = alexnet.features(img)
  features_tensor = torch.from_numpy(features.detach().numpy())

  folder_name = master_path + '/train/' + str(classes[label])
  if not os.path.isdir(folder_name):
    os.mkdir(folder_name)
  torch.save(features_tensor.squeeze(0), folder_name + '/' + str(n) + '.tensor')
  n += 1
print("--------------------------------------")
for img, label in val_loader:
  features = alexnet.features(img)
  features_tensor = torch.from_numpy(features.detach().numpy())

  folder_name = master_path + '/test/' + str(classes[label])
  if not os.path.isdir(folder_name):
    os.mkdir(folder_name)
  torch.save(features_tensor.squeeze(0), folder_name + '/' + str(n) + '.tensor')
  n += 1
print("======================================")
for img, label in test_loader:
  features = alexnet.features(img)
  features_tensor = torch.from_numpy(features.detach().numpy())

  folder_name = master_path + '/val/' + str(classes[label])
  if not os.path.isdir(folder_name):
    os.mkdir(folder_name)
  torch.save(features_tensor.squeeze(0), folder_name + '/' + str(n) + '.tensor')
  n += 1

def get_feature_loader(batch_size):
  master_path = '/base_img'
  train_set = torchvision.datasets.DatasetFolder(master_path+"/train", loader=torch.load, extensions=('.tensor'))
  val_set = torchvision.datasets.DatasetFolder(master_path+"/val", loader=torch.load, extensions=('.tensor'))
  test_set = torchvision.datasets.DatasetFolder(master_path+"/test", loader=torch.load, extensions=('.tensor'))

  train_feature = torch.utils.data.DataLoader(train_set, batch_size=batch_size, 
                                           num_workers=1, shuffle=True)
  val_feature = torch.utils.data.DataLoader(val_set, batch_size=batch_size, 
                                           num_workers=1, shuffle=True)
  test_feature = torch.utils.data.DataLoader(test_set, batch_size=batch_size, 
                                           num_workers=1, shuffle=True)
  return train_feature, val_feature, test_feature

class FaceRec(nn.Module):
      def __init__(self):
          super(FaceRec, self).__init__()
          self.name = "FaceRec"
          self.conv1 = nn.Conv2d(256, 20, 3) #in_channels, out_chanels, kernel_size
          self.pool = nn.MaxPool2d(2, 2) #kernel_size, stride 
         # self.conv2 = nn.Conv2d(128, 10, 3) #in_channels, out_chanels, kernel_size
          self.fc1 = nn.Linear(1400, 300)
          self.fc2 = nn.Linear(300, 7)

      def forward(self, x):
          # print (x.shape)
          x = self.pool(F.relu(self.conv1(x)))
        # x = self.pool(F.relu(self.conv2(x)))
          x = x.view(-1, 1400)
          x = F.relu(self.fc1(x))
          x = self.fc2(x)
          
          return x

# training
use_cuda = True
model = FaceRec()
if use_cuda and torch.cuda.is_available():
  model.cuda()
  print('CUDA is available!  Training on GPU ...')
else:
  print('CUDA is not available.  Training on CPU ...')
train(model, PATH_OF_DATA, batch_size=64, learning_rate=0.002, num_epochs=50)

model_path = get_model_name("FaceRec", batch_size=64, learning_rate=0.002, epoch=49)
plot_training_curve(model_path)

# testing
use_cuda = True
train_feature, val_feature, test_feature = get_feature_loader(1)

test_accuracy = get_accuracy(model, test_feature)
print("Test accuracy: {}".format(test_accuracy))
